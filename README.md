# Low-Rank Adaptation of a Large Language Model 

The code applies LoRA adapters on top of Q/K/V linear layers in Llama attention

final aim is to finetune a LLM which acts like a copilot and complrtes the prompt in the language of python (completes the code) .

used a small validation dataset of codeparrot dataset available in hf 


